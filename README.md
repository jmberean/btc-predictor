# BTC Predictor

Leakage-safe, walk-forward BTC forecasting pipeline with probabilistic forecasts and optional trading evaluation.

## Architecture (text diagram)
1) Data ingestion (CSV or CCXT) -> 2) OHLCV schema validation -> 3) Feature engineering (causal, with available_at) ->
4) Supervised dataset builder (targets + horizons) -> 5) Walk-forward splits (embargoed) ->
6) Model training (baselines, ARIMA/GARCH, LightGBM, LSTM, N-BEATS) ->
7) Evaluation (metrics, calibration, regime stability) -> 8) Artifacts + model registry -> 9) Inference API.

## Project layout
- configs/: small, medium, large run configs
- scripts/: train, evaluate, infer entrypoints
- src/btc_predictor/: core package
- data/: local storage for raw CSVs
- artifacts/: generated by training

## Data schema and availability contract
OHLCV schema:
- timestamp: bar end time (UTC)
- open, high, low, close, volume

Availability:
- Each bar is available at timestamp + ohlcv_delay_minutes (default 5 minutes)
- Features derived from OHLCV inherit this delay
- prediction_time == available_at
- Training only uses rows where max_target_time <= train_end
- Walk-forward adds an embargo at least max_horizon

If you add external features (funding, on-chain, macro), attach their own available_at and take the max when joining.

Feature table (all available_at = timestamp + ohlcv_delay_minutes):
| Feature | Formula | Inputs | Notes |
| --- | --- | --- | --- |
| log_return_1 | log(close/close.shift(1)) | close | 1-step log return |
| log_return_lag_k | log_return_1.shift(k) | close | lagged returns |
| momentum_k | close.pct_change(k) | close | k-step momentum |
| ret_mean_w | rolling mean of log_return_1 | close | mean return |
| ret_std_w | rolling std of log_return_1 | close | volatility proxy |
| realized_vol_w | sqrt(sum(log_return_1^2)) | close | realized vol |
| volume_z_w | (volume-mean)/std | volume | volume z-score |
| price_sma_w | rolling mean / close - 1 | close | price deviation |
| range_pct | (high-low)/close | high, low, close | range |
| rsi | RSI(close, window) | close | momentum |
| atr | ATR(high, low, close) | high, low, close | range |
| drawdown | close/rolling_max - 1 | close | drawdown |
| hour, dow, is_weekend | calendar | timestamp | seasonality |
| vol_regime | rolling std > rolling median | close | regime |
| trend_regime | MA_fast > MA_slow | close | regime |

## Binance bulk data (recommended)
Binance bulk files are the highest quality free source. Download monthly ZIPs once, then run offline.

Downloader examples:
```
set PYTHONPATH=src
python scripts/download_binance_bulk.py --asset spot --data-type klines --data-frequency 1h --symbols BTCUSDT --timeperiod monthly --output-dir data/binance
python scripts/download_binance_bulk.py --asset um --data-type fundingRate --data-frequency 1h --symbols BTCUSDT --timeperiod monthly --output-dir data/binance
python scripts/download_binance_bulk.py --asset um --data-type markPriceKlines --data-frequency 1h --symbols BTCUSDT --timeperiod monthly --output-dir data/binance
python scripts/download_binance_bulk.py --asset um --data-type indexPriceKlines --data-frequency 1h --symbols BTCUSDT --timeperiod monthly --output-dir data/binance
```

Note: Some Binance bulk timestamps after 2025 may switch to microseconds. The loader auto-detects ms vs us.
Note: The downloader mirrors the full monthly/daily directory for the symbol; filter the date range in config `data.start/end`.

## Targets
Default: log returns for each horizon. This improves stationarity and stabilizes error distributions.

## Model roster
Baselines:
- Naive historical quantiles
- Random walk (zero-mean)

Classical:
- ARIMA (mean) with normal quantiles
- GARCH (volatility) with normal quantiles

Tree:
- LightGBM quantile regression

Deep baselines:
- LSTM quantile regression

SOTA candidates (12 primary + 1 secondary):
Primary:
1) Temporal Fusion Transformer (TFT)
2) PatchTST
3) N-HiTS
4) N-BEATSx
5) DeepAR
6) Informer
7) Autoformer
8) FEDformer
9) TimesNet
10) Transformer-XL for time series
11) Temporal Convolutional Network (TCN)
12) Mixer (TSMixer)
Secondary:
- Diffusion-based time series model

Implemented in this repo: N-BEATS (as nbeats) as a SOTA representative; others are drop-in candidates.

## Walk-forward evaluation
- Expanding or rolling scheme
- Embargo >= max horizon
- No random splits

## Metrics
Forecast metrics: MAE, RMSE, sMAPE, MASE, directional accuracy, balanced accuracy, pinball loss, coverage.
Diagnostics: reliability curves, regime stability (high vs low vol), yearly/quarterly slices.

## Trading evaluation (separate)
Optional backtest using thresholded median return, fees and slippage. This is an engineering check, not advice.

## Running
1) Create venv
```
python -m venv .venv
.\.venv\Scripts\activate
pip install -r requirements.txt
```

2) Train (CSV)
```
set PYTHONPATH=src
python scripts/train.py --config configs/small.yaml
```

2b) Train (Binance bulk)
```
set PYTHONPATH=src
python scripts/train.py --config configs/binance_bulk.yaml
```

3) Evaluate
```
set PYTHONPATH=src
python scripts/evaluate.py --artifacts artifacts/<run_id>
```

4) Inference
```
set PYTHONPATH=src
python scripts/infer.py --config configs/small.yaml --model artifacts/<run_id>/models/lightgbm_fold0.joblib
```

5) Leakage time-travel check (optional)
```
set PYTHONPATH=src
python scripts/leakage_check.py --config configs/small.yaml
```

6) Trading evaluation (optional)
```
set PYTHONPATH=src
python scripts/trading_eval.py --artifacts artifacts/<run_id> --horizon 1h
```

## Failure modes and mitigations
- Leakage via lookahead: enforced available_at, embargoed walk-forward, and target_time checks.
- Non-stationarity: log returns, regime features, rolling evaluation.
- Overfitting: walk-forward CV, early stopping for LGBM, regularization in deep models.
- Calibration drift: quantile loss + reliability monitoring, interval coverage checks.
- Data gaps / outages: strict schema validation and modular ingestion (CSV/CCXT).
- Trading optimism: separate evaluation with fees/slippage and no in-sample peeking.

## Substitutes when data is missing
- Funding/open interest unavailable -> use volume-based proxies, realized vol, and basis from spot vs perp if present.
- On-chain unavailable -> use exchange flows from public APIs or omit features (pipeline handles missing joins).
- Macro unavailable -> use equity ETF proxies (SPY/QQQ) or omit.
